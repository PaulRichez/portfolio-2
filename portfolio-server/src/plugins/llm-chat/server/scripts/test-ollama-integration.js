#!/usr/bin/env node

/**
 * Script de test pour l'int√©gration Ollama avec SmartRAGTool
 * Valide que le syst√®me d'analyse IA fonctionne correctement
 */

const axios = require('axios');
const fs = require('fs');
const path = require('path');

// Configuration
const OLLAMA_URL = 'http://localhost:11434';
const QWEN_MODEL = 'qwen3:0.6b';

// Questions de test
const TEST_QUESTIONS = [
  {
    question: "Quels sont tes projets React ?",
    expectedRAG: true,
    expectedKeywords: ["projets", "React"]
  },
  {
    question: "Quel temps fait-il aujourd'hui ?",
    expectedRAG: false,
    expectedKeywords: []
  },
  {
    question: "Comment te contacter ?",
    expectedRAG: true,
    expectedKeywords: ["contact"]
  },
  {
    question: "Peux-tu me parler de ton exp√©rience ?",
    expectedRAG: true,
    expectedKeywords: ["exp√©rience"]
  },
  {
    question: "Que penses-tu de la politique ?",
    expectedRAG: false,
    expectedKeywords: []
  },
  {
    question: "Quelles sont tes comp√©tences en Vue.js ?",
    expectedRAG: true,
    expectedKeywords: ["comp√©tences", "Vue.js"]
  }
];

// Prompt pour Ollama (identique √† celui du SmartRAGTool)
const createAnalysisPrompt = (userMessage) => `Tu es un syst√®me d'analyse intelligent qui d√©termine si une question n√©cessite une recherche dans une base de donn√©es de portfolio.

QUESTION √Ä ANALYSER: "${userMessage}"

CONTEXTE: La base de donn√©es contient des informations sur :
- Projets de d√©veloppement (React, Vue, PHP, etc.)
- Comp√©tences techniques et technologies
- Exp√©riences professionnelles
- Formation et √©ducation
- Informations de contact
- Portfolio personnel

T√ÇCHE: D√©termine si cette question n√©cessite une recherche RAG.

R√âPONDS UNIQUEMENT au format JSON suivant :
{
  "shouldUseRAG": true/false,
  "confidence": 0.0-1.0,
  "keywords": ["mot1", "mot2"],
  "reasoning": "explication courte"
}

Exemples :
- "Quels sont tes projets React ?" ‚Üí shouldUseRAG: true, keywords: ["projets", "React"]
- "Quel temps fait-il ?" ‚Üí shouldUseRAG: false, keywords: []
- "Comment te contacter ?" ‚Üí shouldUseRAG: true, keywords: ["contact"]`;

// Fonctions utilitaires
const colors = {
  reset: '\x1b[0m',
  bright: '\x1b[1m',
  red: '\x1b[31m',
  green: '\x1b[32m',
  yellow: '\x1b[33m',
  blue: '\x1b[34m',
  magenta: '\x1b[35m',
  cyan: '\x1b[36m'
};

const log = (message, color = 'reset') => {
  console.log(`${colors[color]}${message}${colors.reset}`);
};

// Test de connexion Ollama
async function testOllamaConnection() {
  log('üîç Test de connexion Ollama...', 'blue');

  try {
    const response = await axios.get(`${OLLAMA_URL}/api/tags`, { timeout: 5000 });

    if (response.status === 200) {
      log('‚úÖ Ollama est accessible', 'green');

      const models = response.data.models || [];
      const qwenModel = models.find(m => m.name === QWEN_MODEL);

      if (qwenModel) {
        log(`‚úÖ Mod√®le ${QWEN_MODEL} trouv√©`, 'green');
        log(`   Taille: ${Math.round(qwenModel.size / 1024 / 1024)}MB`, 'cyan');
        return true;
      } else {
        log(`‚ùå Mod√®le ${QWEN_MODEL} non trouv√©`, 'red');
        log('   Mod√®les disponibles:', 'yellow');
        models.forEach(m => log(`   - ${m.name}`, 'yellow'));
        return false;
      }
    }
  } catch (error) {
    log(`‚ùå Erreur de connexion Ollama: ${error.message}`, 'red');
    return false;
  }
}

// Test d'analyse avec Ollama
async function testOllamaAnalysis(question) {
  const analysisPrompt = createAnalysisPrompt(question);

  const requestBody = {
    model: QWEN_MODEL,
    prompt: analysisPrompt,
    stream: false,
    options: {
      temperature: 0.1,
      num_ctx: 2048,
      top_p: 0.9
    }
  };

  try {
    const startTime = Date.now();

    const response = await axios.post(`${OLLAMA_URL}/api/generate`, requestBody, {
      timeout: 10000,
      headers: { 'Content-Type': 'application/json' }
    });

    const responseTime = Date.now() - startTime;

    if (response.status === 200) {
      const ollamaResponse = response.data.response;

      // Parser la r√©ponse JSON
      const jsonMatch = ollamaResponse.match(/\{[\s\S]*\}/);
      if (!jsonMatch) {
        throw new Error('Aucun JSON trouv√© dans la r√©ponse Ollama');
      }

      const analysis = JSON.parse(jsonMatch[0]);

      return {
        success: true,
        analysis: {
          shouldUseRAG: Boolean(analysis.shouldUseRAG),
          confidence: Math.max(0, Math.min(1, Number(analysis.confidence) || 0.5)),
          keywords: Array.isArray(analysis.keywords) ? analysis.keywords : [],
          reasoning: String(analysis.reasoning || 'Analyse compl√©t√©e')
        },
        responseTime,
        rawResponse: ollamaResponse
      };
    } else {
      throw new Error(`HTTP ${response.status}: ${response.statusText}`);
    }
  } catch (error) {
    return {
      success: false,
      error: error.message,
      responseTime: 0
    };
  }
}

// Validation des r√©sultats
function validateAnalysis(analysis, expected, question) {
  const issues = [];

  // V√©rifier la d√©cision RAG
  if (analysis.shouldUseRAG !== expected.expectedRAG) {
    issues.push(`RAG d√©cision incorrecte: attendu ${expected.expectedRAG}, re√ßu ${analysis.shouldUseRAG}`);
  }

  // V√©rifier la pr√©sence de mots-cl√©s attendus (souple)
  if (expected.expectedRAG && expected.expectedKeywords.length > 0) {
    const hasExpectedKeywords = expected.expectedKeywords.some(keyword =>
      analysis.keywords.some(k => k.toLowerCase().includes(keyword.toLowerCase()))
    );

    if (!hasExpectedKeywords) {
      issues.push(`Mots-cl√©s manquants: attendus ${expected.expectedKeywords.join(', ')}, re√ßus ${analysis.keywords.join(', ')}`);
    }
  }

  // V√©rifier la confiance
  if (analysis.confidence < 0.5) {
    issues.push(`Confiance faible: ${(analysis.confidence * 100).toFixed(1)}%`);
  }

  return issues;
}

// Test principal
async function runTests() {
  log('üß™ Test de l\'int√©gration Ollama - SmartRAGTool', 'bright');
  log('='.repeat(60), 'cyan');

  // Test de connexion
  const connectionOk = await testOllamaConnection();
  if (!connectionOk) {
    log('‚ùå Tests annul√©s: Ollama non accessible', 'red');
    process.exit(1);
  }

  log(''); // Ligne vide

  // Tests d'analyse
  let successCount = 0;
  let totalResponseTime = 0;
  const results = [];

  for (let i = 0; i < TEST_QUESTIONS.length; i++) {
    const test = TEST_QUESTIONS[i];
    log(`üìù Test ${i + 1}/${TEST_QUESTIONS.length}: "${test.question}"`, 'blue');

    const result = await testOllamaAnalysis(test.question);

    if (result.success) {
      const issues = validateAnalysis(result.analysis, test, test.question);
      totalResponseTime += result.responseTime;

      if (issues.length === 0) {
        log(`‚úÖ Succ√®s (${result.responseTime}ms)`, 'green');
        log(`   RAG: ${result.analysis.shouldUseRAG} | Confiance: ${(result.analysis.confidence * 100).toFixed(1)}%`, 'cyan');
        log(`   Mots-cl√©s: [${result.analysis.keywords.join(', ')}]`, 'cyan');
        log(`   Raison: ${result.analysis.reasoning}`, 'cyan');
        successCount++;
      } else {
        log(`‚ö†Ô∏è  Probl√®me (${result.responseTime}ms)`, 'yellow');
        log(`   RAG: ${result.analysis.shouldUseRAG} | Confiance: ${(result.analysis.confidence * 100).toFixed(1)}%`, 'cyan');
        log(`   Mots-cl√©s: [${result.analysis.keywords.join(', ')}]`, 'cyan');
        issues.forEach(issue => log(`   ‚ö†Ô∏è  ${issue}`, 'yellow'));
      }

      results.push({
        question: test.question,
        success: issues.length === 0,
        analysis: result.analysis,
        responseTime: result.responseTime,
        issues
      });
    } else {
      log(`‚ùå √âchec: ${result.error}`, 'red');
      results.push({
        question: test.question,
        success: false,
        error: result.error,
        responseTime: 0
      });
    }

    log(''); // Ligne vide entre les tests
  }

  // R√©sum√©
  log('üìä R√©sum√© des Tests', 'bright');
  log('='.repeat(60), 'cyan');
  log(`Tests r√©ussis: ${successCount}/${TEST_QUESTIONS.length}`, successCount === TEST_QUESTIONS.length ? 'green' : 'yellow');
  log(`Temps moyen de r√©ponse: ${Math.round(totalResponseTime / TEST_QUESTIONS.length)}ms`, 'cyan');
  log(`Taux de succ√®s: ${Math.round((successCount / TEST_QUESTIONS.length) * 100)}%`, 'cyan');

  // Sauvegarder les r√©sultats
  const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
  const reportPath = path.join(__dirname, `test-results-${timestamp}.json`);

  const report = {
    timestamp: new Date().toISOString(),
    model: QWEN_MODEL,
    totalTests: TEST_QUESTIONS.length,
    successCount,
    successRate: (successCount / TEST_QUESTIONS.length) * 100,
    averageResponseTime: Math.round(totalResponseTime / TEST_QUESTIONS.length),
    results
  };

  fs.writeFileSync(reportPath, JSON.stringify(report, null, 2));
  log(`üìÑ Rapport sauvegard√©: ${reportPath}`, 'magenta');

  // Recommandations
  if (successCount < TEST_QUESTIONS.length) {
    log('', 'reset');
    log('üí° Recommandations:', 'yellow');
    log('   - V√©rifier la qualit√© du prompt d\'analyse', 'yellow');
    log('   - Ajuster la temp√©rature du mod√®le', 'yellow');
    log('   - Consid√©rer un fine-tuning pour ce cas d\'usage', 'yellow');
  } else {
    log('üéâ Tous les tests sont r√©ussis ! L\'int√©gration Ollama fonctionne parfaitement.', 'green');
  }
}

// Ex√©cution
if (require.main === module) {
  runTests().catch(error => {
    log(`üí• Erreur fatale: ${error.message}`, 'red');
    process.exit(1);
  });
}

module.exports = { testOllamaConnection, testOllamaAnalysis, validateAnalysis };
