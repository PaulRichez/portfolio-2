import type { Core } from '@strapi/strapi';

/**
 * Service pour int√©grer Ollama et ses mod√®les
 */
const ollamaService = ({ strapi }: { strapi: Core.Strapi }) => {

  // Configuration par d√©faut d'Ollama
  const getOllamaConfig = () => {
    const pluginConfig = strapi.config.get('plugin::llm-chat') || strapi.plugin('llm-chat').config('default');
    const config = pluginConfig as any;
    return {
      baseUrl: config?.ollama?.baseUrl || process.env.CUSTOM_LLM_BASE_URL || 'http://localhost:11434',
      qwenModel: config?.ollama?.modelName || 'qwen2.5:1.5b'
    };
  };

  /**
   * Appelle le mod√®le qwen3:0.6b pour analyser si le RAG est n√©cessaire
   */
  const shouldUseRAGWithOllama = async (userMessage: string): Promise<{
    shouldUseRAG: boolean;
    confidence: number;
    keywords: string[];
    reasoning: string;
  }> => {
    const timerId = `üß† Ollama RAG Analysis [${Date.now()}]`;
    console.time(timerId);

    try {
      const config = getOllamaConfig();

      // 1. FAST PATH: Regex immediate analysis
      // This drastically speeds up the RAG check for common queries
      const fastPathKeywords = extractBasicKeywords(userMessage);

      // Check for common non-RAG queries (greetings, simple tests) to skip RAG immediately
      const skipKeywords = ['test', 'bonjour', 'salut', 'hello', 'coucou', 'hola', 'hi', '√ßa va', 'ca va'];
      const lowerMsg = userMessage.toLowerCase().trim();
      const shouldSkipRAG = skipKeywords.some(k => lowerMsg === k || lowerMsg.startsWith(k + ' ') || lowerMsg.endsWith(' ' + k));

      if (shouldSkipRAG) {
        console.log('‚ö° Fast Path: Skip RAG detected (greeting/test)');
        return {
          shouldUseRAG: false,
          confidence: 1.0,
          keywords: [],
          reasoning: 'Fast path: greeting or test detected'
        };
      }

      if (fastPathKeywords.length > 0) {
        console.log('‚ö° Fast Path RAG detection: Keywords found, skipping Ollama analysis');

        return {
          shouldUseRAG: true,
          confidence: 1.0,
          keywords: fastPathKeywords,
          reasoning: `Fast Path detection (found: ${fastPathKeywords.join(', ')})`
        };
      }

      // 2. SLOW PATH: Use Ollama for ambiguous queries
      // Removed connection test to save latency - let it fail into catch block if offline
      // console.log('üîç Testing Ollama connection for deep analysis...');
      // const isConnected = await testConnectionQuick();
      // ...

      // Prompt ultra-court optimis√© pour qwen3:0.6b utilis√© par PaulIA
      const analysisPrompt = `Question: "${userMessage}"

PaulIA's database contains: Paul's projects, skills, experience, education, contact info.

JSON response format:
{"shouldUseRAG": true/false, "confidence": 0.9, "keywords": ["word1", "word2"]}

Examples:
"Paul's React projects?" ‚Üí {"shouldUseRAG": true, "confidence": 0.9, "keywords": ["projects", "React"]}
"Weather?" ‚Üí {"shouldUseRAG": false, "confidence": 0.9, "keywords": []}
"Contact Paul?" ‚Üí {"shouldUseRAG": true, "confidence": 0.9, "keywords": ["contact"]}

Response:`;

      console.log(`üß† PaulIA analyzing with Ollama ${config.qwenModel}...`);

      const requestBody = {
        model: config.qwenModel,
        prompt: analysisPrompt,
        stream: false,
        think: false,
        options: {
          temperature: 0.0, // Temp√©rature tr√®s basse pour des r√©ponses d√©terministes
          num_ctx: 512, // Contexte r√©duit de moiti√©
          top_p: 0.1, // Plus restrictif pour acc√©l√©rer
          top_k: 10, // Limite les choix pour acc√©l√©rer
          repeat_penalty: 1.0
        }
      };

      // Utiliser fetch sans AbortController comme dans langchain-service
      const response = await fetch(`${config.baseUrl}/api/generate`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(requestBody)
      });

      if (!response.ok) {
        throw new Error(`Ollama request failed: ${response.status} ${response.statusText}`);
      }

      const data = await response.json() as any; // Type assertion pour √©viter les erreurs TypeScript
      const ollamaResponse = data.response;

      console.log('üéØ Ollama raw response:', ollamaResponse);

      // Parser la r√©ponse JSON
      const jsonMatch = ollamaResponse.match(/\{[\s\S]*\}/);
      if (!jsonMatch) {
        throw new Error('No JSON found in Ollama response');
      }

      const analysis = JSON.parse(jsonMatch[0]);

      // Validation et fallback
      const result = {
        shouldUseRAG: Boolean(analysis.shouldUseRAG),
        confidence: Math.max(0, Math.min(1, Number(analysis.confidence) || 0.9)),
        keywords: Array.isArray(analysis.keywords) ? analysis.keywords : [],
        reasoning: 'Fast analysis' // Reasoning simplifi√©
      };

      console.log('‚úÖ PaulIA Ollama analysis result:', result);
      console.timeEnd(timerId);
      return result;

    } catch (error) {
      console.timeEnd(timerId);
      console.error('‚ùå PaulIA Ollama analysis failed:', error);

      // Fallback √† l'analyse manuelle pour PaulIA en cas d'erreur
      const shouldUseRAG = manualKeywordAnalysis(userMessage);

      return {
        shouldUseRAG,
        confidence: 0.8, // Confiance √©lev√©e pour le fallback de PaulIA
        keywords: shouldUseRAG ? extractBasicKeywords(userMessage) : [],
        reasoning: `PaulIA fallback: ${error instanceof Error ? error.message.substring(0, 50) : 'error'}`
      };
    }
  };

  /**
   * Analyse manuelle de fallback
   */
  const manualKeywordAnalysis = (message: string): boolean => {
    const portfolioKeywords = [
      'projet', 'projects', 'comp√©tence', 'skills', 'exp√©rience', 'experience',
      'formation', 'education', 'contact', 'portfolio', 'cv', 'profil',
      'react', 'vue', 'angular', 'php', 'python', 'javascript', 'typescript',
      'd√©velopp√©', 'd√©veloppement', 'cr√©√©', 'r√©alisation', 'technologies'
    ];

    const lowerMessage = message.toLowerCase();
    return portfolioKeywords.some(keyword => lowerMessage.includes(keyword));
  };

  /**
   * Extraction basique de mots-cl√©s pour le fallback
   */
  const extractBasicKeywords = (message: string): string[] => {
    // Tech keywords
    const techKeywords = [
      'react', 'vue', 'angular', 'php', 'python', 'javascript', 'typescript', 'node', 'nodejs',
      'html', 'css', 'sass', 'scss', 'tailwind', 'bootstrap', 'sql', 'mysql', 'postgres', 'mongodb',
      'docker', 'aws', 'cloud', 'api', 'rest', 'graphql', 'git'
    ];

    // Core portfolio context keywords
    const contextKeywords = [
      'projet', 'project', 'r√©alisations', 'realisations', 'd√©mo', 'demo',
      'comp√©tence', 'skill', 'techno', 'stack', 'ma√Ætrise', 'niveau',
      'exp√©rience', 'experience', 'parcours', 'curriculum', 'cv', 'background',
      'formation', 'education', 'dipl√¥me', '√©tude', '√©cole',
      'contact', 'email', 'mail', 't√©l√©phone', 'tel', 'phone', 'linkedin', 'github',
      'mission', 'travail', 'poste', 'stage', 'alternance',
      'qui es-tu', 'pr√©sente-toi', 'ton nom', 't\'appelles',
      '√¢ge', 'age', 'naissance', 'birth', 'n√© en', 'years old'
    ];

    const lowerMessage = message.toLowerCase();
    const found: string[] = [];

    // Check strict inclusion
    [...techKeywords, ...contextKeywords].forEach(keyword => {
      // Logic for word boundaries or simple inclusion depending on keyword length
      if (keyword.length > 3) {
        if (lowerMessage.includes(keyword)) found.push(keyword);
      } else {
        // for short words like 'cv', 'git', use word boundary check
        if (new RegExp(`\\b${keyword}\\b`, 'i').test(lowerMessage)) found.push(keyword);
      }
    });

    return [...new Set(found)]; // Deduplicate
  };

  /**
   * Test de connexion Ollama rapide
   */
  const testConnectionQuick = async (): Promise<boolean> => {
    try {
      const config = getOllamaConfig();
      const response = await fetch(`${config.baseUrl}/api/tags`, {
        method: 'GET'
      });

      return response.ok;
    } catch (error) {
      return false;
    }
  };

  /**
   * Test de connexion Ollama
   */
  const testConnection = async (): Promise<boolean> => {
    try {
      const config = getOllamaConfig();
      const response = await fetch(`${config.baseUrl}/api/tags`, {
        method: 'GET'
      });

      return response.ok;
    } catch (error) {
      console.error('‚ùå Ollama connection test failed:', error);
      return false;
    }
  };

  /**
   * V√©rifier si le mod√®le qwen3:0.6b est disponible
   */
  const checkQwenModel = async (): Promise<boolean> => {
    try {
      const config = getOllamaConfig();
      const response = await fetch(`${config.baseUrl}/api/tags`);

      if (!response.ok) return false;

      const data = await response.json() as any; // Type assertion pour √©viter les erreurs TypeScript
      const models = data.models || [];

      return models.some((model: any) => model.name === config.qwenModel);
    } catch (error) {
      console.error('‚ùå Failed to check qwen model:', error);
      return false;
    }
  };

  return {
    shouldUseRAGWithOllama,
    testConnection,
    testConnectionQuick,
    checkQwenModel,
    getOllamaConfig
  };
};

export default ollamaService;
