# IntÃ©gration RAG Intelligente avec Ollama

## Vue d'ensemble

Le systÃ¨me de chat utilise maintenant une approche intelligente pour dÃ©cider automatiquement quand utiliser la recherche RAG (Retrieval-Augmented Generation) basÃ©e sur l'IA Ollama avec le modÃ¨le `qwen3:0.6b`.

## Architecture

### ðŸ§  SmartRAGTool - Outil Principal
- **Objectif** : Analyse intelligente automatique avec Ollama
- **ModÃ¨le IA** : `qwen3:0.6b` (lÃ©ger et efficace)
- **FonctionnalitÃ©s** :
  - Analyse automatique de la pertinence de la question
  - Extraction intelligente des mots-clÃ©s
  - Ã‰valuation de confiance (0-100%)
  - Raisonnement expliquÃ©
  - Fallback vers analyse manuelle si Ollama Ã©choue
  - Recherche contextuelle optimisÃ©e

### ðŸ”§ Outils de Support
- **ChromaRetrievalTool** : Recherche simple dans ChromaDB
- **ChromaAdvancedRetrievalTool** : Recherche avec filtres avancÃ©s

## Flux de Fonctionnement

```mermaid
graph TD
    A[Message utilisateur] --> B[SmartRAGTool]
    B --> C[Analyse Ollama qwen3:0.6b]
    C --> D{RAG nÃ©cessaire?}
    D -->|Non| E[RÃ©ponse sans RAG]
    D -->|Oui| F[Extraction mots-clÃ©s IA]
    F --> G[Recherche ChromaDB optimisÃ©e]
    G --> H[RÃ©sultats formatÃ©s avec analyse IA]
    
    C -->|Erreur| I[Fallback analyse manuelle]
    I --> D
```

## Analyse IA avec Ollama

### Prompt OptimisÃ©
Le systÃ¨me utilise un prompt spÃ©cialement conÃ§u pour `qwen3:0.6b` :

```
Tu es un systÃ¨me d'analyse intelligent qui dÃ©termine si une question nÃ©cessite une recherche dans une base de donnÃ©es de portfolio.

QUESTION Ã€ ANALYSER: "[question]"

CONTEXTE: La base de donnÃ©es contient des informations sur :
- Projets de dÃ©veloppement (React, Vue, PHP, etc.)
- CompÃ©tences techniques et technologies
- ExpÃ©riences professionnelles
- Formation et Ã©ducation
- Informations de contact
- Portfolio personnel

RÃ‰PONDS UNIQUEMENT au format JSON suivant :
{
  "shouldUseRAG": true/false,
  "confidence": 0.0-1.0,
  "keywords": ["mot1", "mot2"],
  "reasoning": "explication courte"
}
```

### Exemples d'Analyse IA

| Question | RÃ©sultat IA | Confiance | Mots-clÃ©s |
|----------|-------------|-----------|-----------|
| "Quels sont tes projets React ?" | âœ… RAG nÃ©cessaire | 95% | ["projets", "React"] |
| "Quel temps fait-il ?" | âŒ RAG non nÃ©cessaire | 98% | [] |
| "Comment te contacter ?" | âœ… RAG nÃ©cessaire | 90% | ["contact"] |
| "Peux-tu me parler de tes compÃ©tences ?" | âœ… RAG nÃ©cessaire | 88% | ["compÃ©tences"] |

## Configuration Ollama

### ModÃ¨le RecommandÃ©
- **ModÃ¨le** : `qwen3:0.6b`
- **Taille** : ~522MB
- **Vitesse** : TrÃ¨s rapide
- **PrÃ©cision** : Excellente pour l'analyse de pertinence

### Configuration dans Docker
```yaml
ollama:
  image: ollama/ollama:latest
  ports:
    - "11434:11434"
  command: >
    "ollama serve &
    sleep 10 &&
    ollama pull qwen3:0.6b &&
    wait"
```

## MÃ©canisme de Fallback

En cas d'Ã©chec d'Ollama :

1. **DÃ©tection automatique** de l'erreur
2. **Basculement** vers l'analyse manuelle
3. **Mots-clÃ©s prÃ©dÃ©finis** pour la recherche
4. **Log de l'erreur** pour dÃ©bogage
5. **Fonctionnement continu** garanti

### Mots-clÃ©s de Fallback
```typescript
const portfolioKeywords = [
  // Projets
  'projet', 'projects', 'rÃ©alisation', 'portfolio',
  
  // Technologies
  'react', 'vue', 'angular', 'nodejs', 'php', 'python',
  
  // CompÃ©tences
  'compÃ©tence', 'skills', 'expÃ©rience', 'formation',
  
  // Contact
  'contact', 'email', 'tÃ©lÃ©phone', 'linkedin'
];
```

## Optimisations Performance

### ðŸš€ Recherche Intelligente
- **Nombre de rÃ©sultats adaptatif** selon le contexte
- **RequÃªtes optimisÃ©es** basÃ©es sur l'analyse IA
- **Cache des conversations** pour Ã©viter les re-analyses

### ðŸ“Š MÃ©triques et Logging
```
ðŸ¤– SmartRAGTool: Starting AI analysis with Ollama qwen3:0.6b
ðŸ§  Ollama analysis result: { shouldUseRAG: true, confidence: 0.95, keywords: ["projets", "React"] }
ðŸŽ¯ SmartRAGTool: AI-generated search query: "projets React"
ðŸ” SmartRAG AI Search: 45ms
âœ… SmartRAGTool: Found 3 relevant documents using AI analysis
```

## IntÃ©gration LangChain

### Pour OpenAI (Agent avec outils)
```typescript
const tools = [
  new SmartRAGTool(strapi),           // Principal - IA
  new ChromaRetrievalTool(strapi),    // Support - Simple
  new ChromaAdvancedRetrievalTool(strapi) // Support - AvancÃ©
];
```

### Pour ModÃ¨les Custom (RAG Smart)
```typescript
conversationChains.set(sessionId, {
  type: 'rag_smart',
  model: createModel(config, options),
  smartRAGTool: new SmartRAGTool(strapi),
  memory
});
```

## Avantages de cette Architecture

### ðŸŽ¯ Intelligence Artificielle
- **DÃ©cisions automatiques** basÃ©es sur l'IA
- **Analyse contextuelle** approfondie
- **Apprentissage continu** des patterns

### âš¡ Performance
- **ModÃ¨le lÃ©ger** (qwen3:0.6b)
- **Temps de rÃ©ponse rapide** (~100ms)
- **Fallback robuste** en cas d'erreur

### ðŸ”„ FlexibilitÃ©
- **Compatible** avec tous les providers LLM
- **Extensible** pour nouveaux types de questions
- **Configurable** selon les besoins

### ðŸ›¡ï¸ Robustesse
- **Fallback automatique** si Ollama Ã©choue
- **Logging complet** pour dÃ©bogage
- **Graceful degradation** en cas de problÃ¨me

## Maintenance et Monitoring

### VÃ©rification SantÃ© Ollama
```bash
curl http://localhost:11434/api/tags
```

### Logs Ã  Surveiller
- âœ… SuccÃ¨s d'analyse Ollama
- âŒ Ã‰checs et fallbacks
- ðŸ“Š Temps de rÃ©ponse
- ðŸŽ¯ Pertinence des rÃ©sultats

### MÃ©triques Importantes
- **Taux de succÃ¨s Ollama** (cible: >95%)
- **Temps d'analyse** (cible: <200ms)
- **PrÃ©cision RAG** (Ã©valuation manuelle)
- **Satisfaction utilisateur**

## Ã‰volutions Futures

### ðŸ”® AmÃ©liorations Possibles
- **Fine-tuning** du modÃ¨le sur des donnÃ©es spÃ©cifiques
- **Multi-modÃ¨les** pour diffÃ©rents types de questions
- **Cache intelligent** des analyses rÃ©currentes
- **Apprentissage** des prÃ©fÃ©rences utilisateur

### ðŸ“ˆ Optimisations AvancÃ©es
- **Embedding hybride** (texte + mÃ©tadonnÃ©es)
- **Re-ranking** des rÃ©sultats par pertinence
- **AgrÃ©gation intelligente** de sources multiples
- **Personnalisation** par utilisateur
